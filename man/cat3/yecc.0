yecc(3)                    Erlang Module Definition                    yecc(3)



NNAAMMEE
       yecc - LALR-1 Parser Generator

DDEESSCCRRIIPPTTIIOONN
       An LALR-1 parser generator for Erlang, similar to _y_a_c_c. Takes a BNF
       grammar definition as input, and produces Erlang code for a parser.

       To understand this text, you also have to look at the _y_a_c_c
       documentation in the UNIX(TM) manual. This is most probably necessary
       in order to understand the idea of a parser generator, and the
       principle and problems of LALR parsing with finite look-ahead.

EEXXPPOORRTTSS
       ffiillee((GGrraammmmaarrffiillee [[,, OOppttiioonnss]])) -->> YYeeccccRReett

              Types:

                 Grammarfile = filename()
                 Options = Option | [Option]
                 Option = - see below -
                 YeccRet = {ok, Parserfile} | {ok, Parserfile, Warnings} |
                 error | {error, Warnings, Errors}
                 Parserfile = filename()
                 Warnings = Errors = [{filename(), [ErrorInfo]}]
                 ErrorInfo = {ErrorLine, module(), Reason}
                 ErrorLine = integer()
                 Reason = - formatable by format_error/1 -

              _G_r_a_m_m_a_r_f_i_l_e is the file of declarations and grammar rules.
              Returns _o_k upon success, or _e_r_r_o_r if there are errors. An Erlang
              file containing the parser is created if there are no errors.
              The options are:

                _{_p_a_r_s_e_r_f_i_l_e_, _P_a_r_s_e_r_f_i_l_e_}.:
                  _P_a_r_s_e_r_f_i_l_e is the name of the file that will contain the
                  Erlang parser code that is generated. The default (_"_") is to
                  add the extension _._e_r_l to _G_r_a_m_m_a_r_f_i_l_e stripped of the _._y_r_l
                  extension.

                _{_i_n_c_l_u_d_e_f_i_l_e_, _I_n_c_l_u_d_e_f_i_l_e_}.:
                  Indicates a customized prologue file which the user may want
                  to use instead of the default file
                  _l_i_b_/_p_a_r_s_e_t_o_o_l_s_/_i_n_c_l_u_d_e_/_y_e_c_c_p_r_e_._h_r_l which is otherwise
                  included at the beginning of the resulting parser file. _N_._B_.
                  The _I_n_c_l_u_d_e_f_i_l_e is included 'as is' in the parser file, so
                  it must not have a module declaration of its own, and it
                  should not be compiled. It must, however, contain the
                  necessary export declarations. The default is indicated by
                  _"_".

                _{_r_e_p_o_r_t___e_r_r_o_r_s_, _b_o_o_l_(_)_}.:
                  Causes errors to be printed as they occur. Default is _t_r_u_e.

                _{_r_e_p_o_r_t___w_a_r_n_i_n_g_s_, _b_o_o_l_(_)_}.:
                  Causes warnings to be printed as they occur. Default is
                  _t_r_u_e.

                _{_r_e_p_o_r_t_, _b_o_o_l_(_)_}.:
                  This is a short form for both _r_e_p_o_r_t___e_r_r_o_r_s and
                  _r_e_p_o_r_t___w_a_r_n_i_n_g_s.

                _w_a_r_n_i_n_g_s___a_s___e_r_r_o_r_s:
                  Causes warnings to be treated as errors.

                _{_r_e_t_u_r_n___e_r_r_o_r_s_, _b_o_o_l_(_)_}.:
                  If this flag is set, _{_e_r_r_o_r_, _E_r_r_o_r_s_, _W_a_r_n_i_n_g_s_} is returned
                  when there are errors. Default is _f_a_l_s_e.

                _{_r_e_t_u_r_n___w_a_r_n_i_n_g_s_, _b_o_o_l_(_)_}.:
                  If this flag is set, an extra field containing _W_a_r_n_i_n_g_s is
                  added to the tuple returned upon success. Default is _f_a_l_s_e.

                _{_r_e_t_u_r_n_, _b_o_o_l_(_)_}.:
                  This is a short form for both _r_e_t_u_r_n___e_r_r_o_r_s and
                  _r_e_t_u_r_n___w_a_r_n_i_n_g_s.

                _{_v_e_r_b_o_s_e_, _b_o_o_l_(_)_}. :
                  Determines whether the parser generator should give full
                  information about resolved and unresolved parse action
                  conflicts (_t_r_u_e), or only about those conflicts that prevent
                  a parser from being generated from the input grammar (_f_a_l_s_e,
                  the default).

              Any of the Boolean options can be set to _t_r_u_e by stating the
              name of the option. For example, _v_e_r_b_o_s_e is equivalent to
              _{_v_e_r_b_o_s_e_, _t_r_u_e_}.

              The value of the _P_a_r_s_e_r_f_i_l_e option stripped of the _._e_r_l
              extension is used by Yecc as the module name of the generated
              parser file.

              Yecc will add the extension _._y_r_l to the _G_r_a_m_m_a_r_f_i_l_e name, the
              extension _._h_r_l to the _I_n_c_l_u_d_e_f_i_l_e name, and the extension _._e_r_l
              to the _P_a_r_s_e_r_f_i_l_e name, unless the extension is already there.

       ffoorrmmaatt__eerrrroorr((RReeaassoonn)) -->> CChhaarrss

              Types:

                 Reason = - as returned by yecc:file/1,2 -
                 Chars = [char() | Chars]

              Returns a descriptive string in English of an error tuple
              returned by _y_e_c_c_:_f_i_l_e_/_1_,_2. This function is mainly used by the
              compiler invoking Yecc.

PPRREE--PPRROOCCEESSSSIINNGG
       A _s_c_a_n_n_e_r to pre-process the text (program, etc.) to be parsed is not
       provided in the _y_e_c_c module. The scanner serves as a kind of lexicon
       look-up routine. It is possible to write a grammar that uses only
       character tokens as terminal symbols, thereby eliminating the need for
       a scanner, but this would make the parser larger and slower.

       The user should implement a scanner that segments the input text, and
       turns it into one or more lists of tokens. Each token should be a tuple
       containing information about syntactic category, position in the text
       (e.g. line number), and the actual terminal symbol found in the text:
       _{_C_a_t_e_g_o_r_y_, _L_i_n_e_N_u_m_b_e_r_, _S_y_m_b_o_l_}.

       If a terminal symbol is the only member of a category, and the symbol
       name is identical to the category name, the token format may be
       _{_S_y_m_b_o_l_, _L_i_n_e_N_u_m_b_e_r_}.

       A list of tokens produced by the scanner should end with a special
       _e_n_d___o_f___i_n_p_u_t tuple which the parser is looking for. The format of this
       tuple should be _{_E_n_d_s_y_m_b_o_l_, _L_a_s_t_L_i_n_e_N_u_m_b_e_r_}, where _E_n_d_s_y_m_b_o_l is an
       identifier that is distinguished from all the terminal and non-terminal
       categories of the syntax rules. The _E_n_d_s_y_m_b_o_l may be declared in the
       grammar file (see below).

       The simplest case is to segment the input string into a list of
       identifiers (atoms) and use those atoms both as categories and values
       of the tokens. For example, the input string _a_a_a _b_b_b _7_7_7_, _X may be
       scanned (tokenized) as:

       [{aaa, 1}, {bbb, 1}, {777, 1}, {',' , 1}, {'X', 1},
        {'$end', 1}].

       This assumes that this is the first line of the input text, and that
       _'_$_e_n_d_' is the distinguished _e_n_d___o_f___i_n_p_u_t symbol.

       The Erlang scanner in the _i_o module can be used as a starting point
       when writing a new scanner. Study _y_e_c_c_s_c_a_n_._e_r_l in order to see how a
       filter can be added on top of _i_o_:_s_c_a_n___e_r_l___f_o_r_m_/_3 to provide a scanner
       for Yecc that tokenizes grammar files before parsing them with the Yecc
       parser. A more general approach to scanner implementation is to use a
       scanner generator. A scanner generator in Erlang called _l_e_e_x is under
       development.

GGRRAAMMMMAARR DDEEFFIINNIITTIIOONN FFOORRMMAATT
       Erlang style _c_o_m_m_e_n_t_s, starting with a _'_%_', are allowed in grammar
       files.

       Each _d_e_c_l_a_r_a_t_i_o_n or _r_u_l_e ends with a dot (the character _'_._').

       The grammar starts with an optional _h_e_a_d_e_r section. The header is put
       first in the generated file, before the module declaration. The purpose
       of the header is to provide a means to make the documentation generated
       by _E_D_o_c look nicer. Each header line should be enclosed in double
       quotes, and newlines will be inserted between the lines. For example:

       Header "%% Copyright (C)"
       "%% @private"
       "%% @Author John"

       Next comes a declaration of the _n_o_n_t_e_r_m_i_n_a_l _c_a_t_e_g_o_r_i_e_s to be used in
       the rules. For example:

       Nonterminals sentence nounphrase verbphrase.

       A non-terminal category can be used at the left hand side (= _l_h_s, or
       _h_e_a_d) of a grammar rule. It can also appear at the right hand side of
       rules.

       Next comes a declaration of the _t_e_r_m_i_n_a_l _c_a_t_e_g_o_r_i_e_s, which are the
       categories of tokens produced by the scanner. For example:

       Terminals article adjective noun verb.

       Terminal categories may only appear in the right hand sides (= _r_h_s) of
       grammar rules.

       Next comes a declaration of the _r_o_o_t_s_y_m_b_o_l, or start category of the
       grammar. For example:

       Rootsymbol sentence.

       This symbol should appear in the lhs of at least one grammar rule. This
       is the most general syntactic category which the parser ultimately will
       parse every input string into.

       After the rootsymbol declaration comes an optional declaration of the
       _e_n_d___o_f___i_n_p_u_t symbol that your scanner is expected to use. For example:

       Endsymbol '$end'.

       Next comes one or more declarations of _o_p_e_r_a_t_o_r _p_r_e_c_e_d_e_n_c_e_s, if needed.
       These are used to resolve shift/reduce conflicts (see _y_a_c_c
       documentation).

       Examples of operator declarations:

       Right 100 '='.
       Nonassoc 200 '==' '=/='.
       Left 300 '+'.
       Left 400 '*'.
       Unary 500 '-'.

       These declarations mean that _'_=_' is defined as a _r_i_g_h_t _a_s_s_o_c_i_a_t_i_v_e
       _b_i_n_a_r_y operator with precedence 100, _'_=_=_' and _'_=_/_=_' are operators with
       _n_o _a_s_s_o_c_i_a_t_i_v_i_t_y, _'_+_' and _'_*_' are _l_e_f_t _a_s_s_o_c_i_a_t_i_v_e _b_i_n_a_r_y operators,
       where _'_*_' takes precedence over _'_+_' (the normal case), and _'_-_' is a
       _u_n_a_r_y operator of higher precedence than _'_*_'. The fact that '==' has no
       associativity means that an expression like _a _=_= _b _=_= _c is considered a
       syntax error.

       Certain rules are assigned precedence: each rule gets its precedence
       from the last terminal symbol mentioned in the right hand side of the
       rule. It is also possible to declare precedence for non-terminals, "one
       level up". This is practical when an operator is overloaded (see also
       example 3 below).

       Next come the _g_r_a_m_m_a_r _r_u_l_e_s. Each rule has the general form

       Left_hand_side -> Right_hand_side : Associated_code.

       The left hand side is a non-terminal category. The right hand side is a
       sequence of one or more non-terminal or terminal symbols with spaces
       between. The associated code is a sequence of zero or more Erlang
       expressions (with commas _'_,_' as separators). If the associated code is
       empty, the separating colon _'_:_' is also omitted. A final dot marks the
       end of the rule.

       Symbols such as _'_{_', _'_._', etc., have to be enclosed in single quotes
       when used as terminal or non-terminal symbols in grammar rules. The use
       of the symbols _'_$_e_m_p_t_y_', _'_$_e_n_d_', and _'_$_u_n_d_e_f_i_n_e_d_' should be avoided.

       The last part of the grammar file is an optional section with Erlang
       code (= function definitions) which is included 'as is' in the
       resulting parser file. This section must start with the pseudo
       declaration, or key words

       Erlang code.

       No syntax rule definitions or other declarations may follow this
       section. To avoid conflicts with internal variables, do not use
       variable names beginning with two underscore characters ('__') in the
       Erlang code in this section, or in the code associated with the
       individual syntax rules.

       The optional _e_x_p_e_c_t declaration can be placed anywhere before the last
       optional section with Erlang code. It is used for suppressing the
       warning about conflicts that is ordinarily given if the grammar is
       ambiguous. An example:

       Expect 2.

       The warning is given if the number of shift/reduce conflicts differs
       from 2, or if there are reduce/reduce conflicts.

EEXXAAMMPPLLEESS
       A grammar to parse list expressions (with empty associated code):

       Nonterminals list elements element.
       Terminals atom '(' ')'.
       Rootsymbol list.
       list -> '(' ')'.
       list -> '(' elements ')'.
       elements -> element.
       elements -> element elements.
       element -> atom.
       element -> list.

       This grammar can be used to generate a parser which parses list
       expressions, such as _(_)_, _(_a_)_, _(_p_e_t_e_r _c_h_a_r_l_e_s_)_, _(_a _(_b _c_) _d _(_(_)_)_)_, _._._.
       provided that your scanner tokenizes, for example, the input _(_p_e_t_e_r
       _c_h_a_r_l_e_s_) as follows:

       [{'(', 1} , {atom, 1, peter}, {atom, 1, charles}, {')', 1},
        {'$end', 1}]

       When a grammar rule is used by the parser to parse (part of) the input
       string as a grammatical phrase, the associated code is evaluated, and
       the value of the last expression becomes the value of the parsed
       phrase. This value may be used by the parser later to build structures
       that are values of higher phrases of which the current phrase is a
       part. The values initially associated with terminal category phrases,
       i.e. input tokens, are the token tuples themselves.

       Below is an example of the grammar above with structure building code
       added:

       list -> '(' ')' : nil.
       list -> '(' elements ')' : '$2'.
       elements -> element : {cons, '$1', nil}.
       elements -> element elements : {cons, '$1', '$2'}.
       element -> atom : '$1'.
       element -> list : '$1'.

       With this code added to the grammar rules, the parser produces the
       following value (structure) when parsing the input string _(_a _b _c_)_..
       This still assumes that this was the first input line that the scanner
       tokenized:

       {cons, {atom, 1, a,} {cons, {atom, 1, b},
                                   {cons, {atom, 1, c}, nil}}}

       The associated code contains _p_s_e_u_d_o _v_a_r_i_a_b_l_e_s _'_$_1_', _'_$_2_', _'_$_3_', etc.
       which refer to (are bound to) the values associated previously by the
       parser with the symbols of the right hand side of the rule. When these
       symbols are terminal categories, the values are token tuples of the
       input string (see above).

       The associated code may not only be used to build structures associated
       with phrases, but may also be used for syntactic and semantic tests,
       printout actions (for example for tracing), etc. during the parsing
       process. Since tokens contain positional (line number) information, it
       is possible to produce error messages which contain line numbers. If
       there is no associated code after the right hand side of the rule, the
       value _'_$_u_n_d_e_f_i_n_e_d_' is associated with the phrase.

       The right hand side of a grammar rule may be empty. This is indicated
       by using the special symbol _'_$_e_m_p_t_y_' as rhs. Then the list grammar
       above may be simplified to:

       list -> '(' elements ')' : '$2'.
       elements -> element elements : {cons, '$1', '$2'}.
       elements -> '$empty' : nil.
       element -> atom : '$1'.
       element -> list : '$1'.

GGEENNEERRAATTIINNGG AA PPAARRSSEERR
       To call the parser generator, use the following command:

       yecc:file(Grammarfile).

       An error message from Yecc will be shown if the grammar is not of the
       LALR type (for example too ambiguous). Shift/reduce conflicts are
       resolved in favor of shifting if there are no operator precedence
       declarations. Refer to the _y_a_c_c documentation on the use of operator
       precedence.

       The output file contains Erlang source code for a parser module with
       module name equal to the _P_a_r_s_e_r_f_i_l_e parameter. After compilation, the
       parser can be called as follows (the module name is assumed to be
       _m_y_p_a_r_s_e_r):

       myparser:parse(myscanner:scan(Inport))

       The call format may be different if a customized prologue file has been
       included when generating the parser instead of the default file
       _l_i_b_/_p_a_r_s_e_t_o_o_l_s_/_i_n_c_l_u_d_e_/_y_e_c_c_p_r_e_._h_r_l.

       With the standard prologue, this call will return either _{_o_k_, _R_e_s_u_l_t_},
       where _R_e_s_u_l_t is a structure that the Erlang code of the grammar file
       has built, or _{_e_r_r_o_r_, _{_L_i_n_e___n_u_m_b_e_r_, _M_o_d_u_l_e_, _M_e_s_s_a_g_e_}_} if there was a
       syntax error in the input.

       _M_e_s_s_a_g_e is something which may be converted into a string by calling
       _M_o_d_u_l_e_:_f_o_r_m_a_t___e_r_r_o_r_(_M_e_s_s_a_g_e_) and printed with _i_o_:_f_o_r_m_a_t_/_3.

   NNoottee::
       By default, the parser that was generated will not print out error
       messages to the screen. The user will have to do this either by
       printing the returned error messages, or by inserting tests and print
       instructions in the Erlang code associated with the syntax rules of the
       grammar file.


       It is also possible to make the parser ask for more input tokens when
       needed if the following call format is used:

       myparser:parse_and_scan({Function, Args})
       myparser:parse_and_scan({Mod, Tokenizer, Args})

       The tokenizer _F_u_n_c_t_i_o_n is either a fun or a tuple _{_M_o_d_, _T_o_k_e_n_i_z_e_r_}. The
       call _a_p_p_l_y_(_F_u_n_c_t_i_o_n_, _A_r_g_s_) or _a_p_p_l_y_(_{_M_o_d_, _T_o_k_e_n_i_z_e_r_}_, _A_r_g_s_) is executed
       whenever a new token is needed. This, for example, makes it possible to
       parse from a file, token by token.

       The tokenizer used above has to be implemented so as to return one of
       the following:

       {ok, Tokens, Endline}
       {eof, Endline}
       {error, Error_description, Endline}

       This conforms to the format used by the scanner in the Erlang _i_o
       library module.

       If _{_e_o_f_, _E_n_d_l_i_n_e_} is returned immediately, the call to _p_a_r_s_e___a_n_d___s_c_a_n_/_1
       returns _{_o_k_, _e_o_f_}. If _{_e_o_f_, _E_n_d_l_i_n_e_} is returned before the parser
       expects end of input, _p_a_r_s_e___a_n_d___s_c_a_n_/_1 will, of course, return an error
       message (see above). Otherwise _{_o_k_, _R_e_s_u_l_t_} is returned.

MMOORREE EEXXAAMMPPLLEESS
       1. A grammar for parsing infix arithmetic expressions into prefix
       notation, without operator precedence:

       Nonterminals E T F.
       Terminals '+' '*' '(' ')' number.
       Rootsymbol E.
       E -> E '+' T: ['$2', '$1', '$3'].
       E -> T : '$1'.
       T -> T '*' F: ['$2', '$1', '$3'].
       T -> F : '$1'.
       F -> '(' E ')' : '$2'.
       F -> number : '$1'.

       2. The same with operator precedence becomes simpler:

       Nonterminals E.
       Terminals '+' '*' '(' ')' number.
       Rootsymbol E.
       Left 100 '+'.
       Left 200 '*'.
       E -> E '+' E : ['$2', '$1', '$3'].
       E -> E '*' E : ['$2', '$1', '$3'].
       E -> '(' E ')' : '$2'.
       E -> number : '$1'.

       3. An overloaded minus operator:

       Nonterminals E uminus.
       Terminals '*' '-' number.
       Rootsymbol E.

       Left 100 '-'.
       Left 200 '*'.
       Unary 300 uminus.

       E -> E '-' E.
       E -> E '*' E.
       E -> uminus.
       E -> number.

       uminus -> '-' E.

       4. The Yecc grammar that is used for parsing grammar files, including
       itself:

       Nonterminals
       grammar declaration rule head symbol symbols attached_code
       token tokens.
       Terminals
       atom float integer reserved_symbol reserved_word string char var
       Rootsymbol grammar.
       Endsymbol '$end'.
       grammar -> declaration : '$1'.
       grammar -> rule : '$1'.
       declaration -> symbol symbols dot: {'$1', '$2'}.
       rule -> head '->' symbols attached_code dot: {rule, ['$1' | '$3'],
               '$4'}.
       head -> symbol : '$1'.
       symbols -> symbol : ['$1'].
       symbols -> symbol symbols : ['$1' | '$2'].
       attached_code -> ':' tokens : {erlang_code, '$2'}.
       attached_code -> '$empty' : {erlang_code,
                        [{atom, 0, '$undefined'}]}.
       tokens -> token : ['$1'].
       tokens -> token tokens : ['$1' | '$2'].
       symbol -> var : value_of('$1').
       symbol -> atom : value_of('$1').
       symbol -> integer : value_of('$1').
       symbol -> reserved_word : value_of('$1').
       token -> var : '$1'.
       token -> atom : '$1'.
       token -> float : '$1'.
       token -> integer : '$1'.
       token -> string : '$1'.
       token -> char : '$1'.
       token -> reserved_symbol : {value_of('$1'), line_of('$1')}.
       token -> reserved_word : {value_of('$1'), line_of('$1')}.
       token -> '->' : {'->', line_of('$1')}.
       token -> ':' : {':', line_of('$1')}.
       Erlang code.
       value_of(Token) ->
           element(3, Token).
       line_of(Token) ->
           element(2, Token).

   NNoottee::
       The symbols _'_-_>_', and _'_:_' have to be treated in a special way, as they
       are meta symbols of the grammar notation, as well as terminal symbols
       of the Yecc grammar.


       5. The file _e_r_l___p_a_r_s_e_._y_r_l in the _l_i_b_/_s_t_d_l_i_b_/_s_r_c directory contains the
       grammar for Erlang.

   NNoottee::
       Syntactic tests are used in the code associated with some rules, and an
       error is thrown (and caught by the generated parser to produce an error
       message) when a test fails. The same effect can be achieved with a call
       to _r_e_t_u_r_n___e_r_r_o_r_(_E_r_r_o_r___l_i_n_e_, _M_e_s_s_a_g_e___s_t_r_i_n_g_), which is defined in the
       _y_e_c_c_p_r_e_._h_r_l default header file.


FFIILLEESS
       lib/parsetools/include/yeccpre.hrl

SSEEEE AALLSSOO
       Aho & Johnson: 'LR Parsing', ACM Computing Surveys, vol. 6:2, 1974.



Ericsson AB                    parsetools 2.0.7                        yecc(3)
